{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854488f2",
   "metadata": {},
   "source": [
    "# üöÄ OpenAI Python SDK 101\n",
    "\n",
    "In this notebook we‚Äôll learn how to interact with Large Language Models (LLMs) directly using the **OpenAI Python SDK**.  \n",
    "This is the **first time** we‚Äôre exploring API interactions, so we‚Äôll build up gradually:\n",
    "\n",
    "1. **Initialize** the client with your API key.  \n",
    "2. **Minimal call** to the API (Responses API).  \n",
    "3. Use **Chat Completions** for system + user roles.  \n",
    "4. Explore **temperature** (randomness) and **top_p** (nucleus sampling).  \n",
    "5. Add **system prompts** to guide behavior.  \n",
    "6. Try **streaming tokens** (like ChatGPT typing).  \n",
    "7. Get **JSON/structured outputs** with schemas.  \n",
    "8. Handle **errors, timeouts, and retries** gracefully.\n",
    "\n",
    "By the end, you‚Äôll know how to **call an LLM safely and flexibly** using just the OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844e5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf239a",
   "metadata": {},
   "source": [
    "### API key\n",
    "- Set your OpenAI API key as an environment variable:  \n",
    "  `export OPENAI_API_KEY=\"sk-...\"` (macOS/Linux) or `setx OPENAI_API_KEY \"sk-...\"` (Windows, new terminal required).  \n",
    "- In Colab: use `os.environ[\"OPENAI_API_KEY\"] = \"...\"` (for demos only).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e911ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Python SDK v1 style\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9cd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature controls the randomness of predictions (lower values lead to more deterministic outputs), while top_p (nucleus sampling) limits the selection to a subset of possible next words based on cumulative probability, ensuring diversity while maintaining cohesiveness.\n"
     ]
    }
   ],
   "source": [
    "# Minimal \"Responses API\" call (recommended by OpenAI for new projects)\n",
    "# Docs: https://platform.openai.com/docs/guides/text  and Responses vs Chat Completions\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",  # choose any available text-capable model\n",
    "    input=\"In one sentence, explain the difference between temperature and top_p for sampling.\"\n",
    ")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fd52e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0411737713c487660069070cd5beec819f980091a5ff0f3c05', created_at=1762069717.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0411737713c487660069070cd69ee0819fbf49baa0bbb34bf3', content=[ResponseOutputText(annotations=[], text='Temperature controls the randomness of predictions (lower values lead to more deterministic outputs), while top_p (nucleus sampling) limits the selection to a subset of possible next words based on cumulative probability, ensuring diversity while maintaining cohesiveness.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=22, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=46, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=68), user=None, billing={'payer': 'developer'}, prompt_cache_retention=None, store=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff892c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and outliers, which results in poor generalization to new, unseen data.\n",
      "\n",
      "- **Symptoms**: Indications of overfitting include high accuracy on the training set but significantly lower accuracy on the validation or test set, suggesting that the model is too complex.\n",
      "\n",
      "- **Prevention Techniques**: Common strategies to mitigate overfitting include using simpler models, applying regularization techniques (like L1 or L2 penalties), and employing cross-validation and dropout in neural networks.\n"
     ]
    }
   ],
   "source": [
    "# Using Chat Completions (still widely used & supported)\n",
    "chat = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise teaching assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me 3 bullet points about overfitting.\"},\n",
    "    ],\n",
    ")\n",
    "print(chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01254fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CXN7R9ZRS3l3frHZa9QvfRZWWj5jx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='- **Definition**: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and outliers, which results in poor generalization to new, unseen data.\\n\\n- **Symptoms**: Indications of overfitting include high accuracy on the training set but significantly lower accuracy on the validation or test set, suggesting that the model is too complex.\\n\\n- **Prevention Techniques**: Common strategies to mitigate overfitting include using simpler models, applying regularization techniques (like L1 or L2 penalties), and employing cross-validation and dropout in neural networks.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762069729, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=118, prompt_tokens=29, total_tokens=147, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5dddecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can reverse a string in Python using slicing. Here's a simple example:\n",
      "\n",
      "```python\n",
      "original_string = \"Hello, World!\"\n",
      "reversed_string = original_string[::-1]\n",
      "print(reversed_string)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```\n",
      "!dlroW ,olleH\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python tutor who answers with short code examples.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Show how to reverse a string in Python.\"}\n",
    "]\n",
    "r = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, temperature=0)\n",
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63fd12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can reverse a string in Python using slicing. Here's an example:\n",
      "\n",
      "```python\n",
      "original_string = \"Hello, World!\"\n",
      "reversed_string = original_string[::-1]\n",
      "print(reversed_string)  # Output: !dlroW ,olleH\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "r = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, temperature=1)\n",
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553e975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a cozy little village, there lived a cat named Whiskers and a dog named Max. Whiskers was a sleek, gray tabby with striking green eyes, while Max was a jovial golden retriever with a heart as big as his bark. They lived on neighboring farms, and while their owners were friends, Whiskers and Max had never quite seen eye to eye.\n",
      "\n",
      "Whiskers prided herself on her independence and grace. She spent her days prowling the rooftops, napping in sunbeams, and meticulously grooming her fur. Max, on the other hand, was all about fun and adventure. He loved to chase after sticks, dig in the dirt, and wag his tail at every passerby.\n",
      "\n",
      "One bright summer morning, a ruckus erupted in the village square. A mischievous little squirrel was darting about, stealing shiny trinkets from the market stalls. The villagers were in a frenzy, trying to catch the speedy thief. Whiskers watched from her perch on a fence, her curiosity piqued. Max, with his boundless energy, leapt into action, barking excitedly as he chased the squirrel.\n",
      "\n",
      "As the squirrel zipped past Whiskers, she caught his eye and, without thinking, leaped down from the fence. ‚ÄúYou‚Äôll never catch him that way!‚Äù she called to Max, who paused, panting and bewildered.\n",
      "\n",
      "‚ÄúOh, really? And how would you do it?‚Äù Max replied, his tail drooping slightly.\n",
      "\n",
      "‚ÄúFollow my lead,‚Äù Whiskers said, flicking her tail with confidence. ‚ÄúI‚Äôll distract him from above, and you can catch him from below.‚Äù\n",
      "\n",
      "Max blinked, surprised by her suggestion. He had always thought cats were aloof and uninterested in teamwork. But there was something about Whiskers‚Äô determination that sparked a glimmer of hope.\n",
      "\n",
      "Together, they devised a plan. Whiskers climbed to the top of a nearby apple tree, her eyes fixed on the squirrel, while Max circled the base, keeping his eyes peeled for any signs of movement. With a swift leap, Whiskers gracefully hopped from branch to branch, creating a rustling sound that caught the squirrel‚Äôs attention.\n",
      "\n",
      "‚ÄúOver here!‚Äù Whiskers called out, her voice playful yet commanding. The squirrel, intrigued by the noise, scampered toward the tree, thinking it was another shiny object to snatch.\n",
      "\n",
      "In that moment, Max sprang into action. With a bound, he leaped toward the base of the tree, barking loudly. The squirrel, startled, darted back up the trunk, but Whiskers was ready. She jumped down from her perch, landing softly beside Max.\n",
      "\n",
      "‚ÄúNow!‚Äù she shouted.\n",
      "\n",
      "Max lunged forward, and together, they managed to corner the squirrel. Realizing it was outnumbered, the squirrel surrendered, dropping the shiny button it had stolen and making a hasty retreat.\n",
      "\n",
      "The villagers erupted in cheers, clapping for the unlikely duo. Max, panting with excitement, turned to Whiskers, his eyes shining. ‚ÄúWe did it! I never would have thought to work together like that.‚Äù\n",
      "\n",
      "Whiskers, her fur slightly ruffled but her spirit soaring, smiled back. ‚ÄúSometimes, it takes a little teamwork to achieve great things.‚Äù\n",
      "\n",
      "From that day on, Whiskers and Max became the best of friends. They spent their afternoons exploring the village, with Max teaching Whiskers how to enjoy the occasional romp in the grass, and Whiskers showing Max the art of climbing trees to watch the sunset from above. They proved that even the most different of friends can create a bond as strong as any.\n",
      "\n",
      "And so, in their little village, the cat and dog became legends, a reminder that friendship knows no bounds, and that sometimes, it‚Äôs the most unexpected partnerships that lead to the greatest adventures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import stdout\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a cat and a dog.\"}],\n",
    "    temperature=0.7,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if hasattr(event, \"choices\"):\n",
    "        delta = event.choices[0].delta\n",
    "        if delta and delta.content:\n",
    "            stdout.write(delta.content)\n",
    "stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd5925f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"item\": \"Rice\",\n",
      "        \"quantity\": \"3 kg\"\n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Dhal\",\n",
      "        \"quantity\": \"4 kg\"\n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Biscuits\",\n",
      "        \"quantity\": \"3 packets\"\n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Sugar\",\n",
      "        \"quantity\": \"2 kg\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"I have bought 3 kg of Rice, 4 kg of dhal, 3 packets of biscuits, 2 kg of sugar.\n",
    "\n",
    "Format this as a list of json objects with each JSON object in the following format:\n",
    "{\n",
    "    \"item\": \"item name\",\n",
    "    \"quantity\": \"quantity\"\n",
    "}\n",
    "\n",
    "DO NOT include anything else in your response.\"\"\"\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f1c926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = completion.choices[0].message.content\n",
    "\n",
    "items = json.loads(response)\n",
    "type(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e11846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rice\n",
      "Dhal\n",
      "Biscuits\n",
      "Sugar\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    print(item[\"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7efd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary(topic='Transformers in NLP', key_points=['Transformers utilize self-attention mechanisms to weigh the importance of different words in a sentence, allowing for better context understanding.', 'They enable parallel processing of data, significantly speeding up training times compared to traditional sequential models like RNNs.', 'Transformers have led to the development of powerful pre-trained models (e.g., BERT, GPT) that can be fine-tuned for various NLP tasks, achieving state-of-the-art results.'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    topic: str\n",
    "    key_points: List[str]\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    response_format=Summary,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Topic: Transformers in NLP. Give 3 key points.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "parsed = completion.choices[0].message.parsed\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334e5e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Summary"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6d077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items=[ShoppingItem(item='Rice', quantity=3), ShoppingItem(item='Dhal', quantity=4), ShoppingItem(item='Biscuits', quantity=3), ShoppingItem(item='Sugar', quantity=2)]\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"I have bought 3 kg of Rice, 4 kg of dhal, 3 packets of biscuits, 2 kg of sugar.\"\"\"\n",
    "\n",
    "\n",
    "class ShoppingItem(BaseModel):\n",
    "    item: str\n",
    "    quantity: int\n",
    "\n",
    "class ShoppingList(BaseModel):\n",
    "    items: List[ShoppingItem]\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    response_format=ShoppingList,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6b0878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShoppingList(items=[ShoppingItem(item='Rice', quantity=3), ShoppingItem(item='Dhal', quantity=4), ShoppingItem(item='Biscuits', quantity=3), ShoppingItem(item='Sugar', quantity=2)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3afffb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"items\":[{\"item\":\"Rice\",\"quantity\":3},{\"item\":\"Dhal\",\"quantity\":4},{\"item\":\"Biscuits\",\"quantity\":3},{\"item\":\"Sugar\",\"quantity\":2}]}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
